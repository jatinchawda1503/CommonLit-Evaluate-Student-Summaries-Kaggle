{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\nüåü **@NOGAWANOGAWA**: Thank you for your generosity in sharing such valuable information! üôè\n\nüî• **@OLEKSIY KONONENKO**: Immensely grateful for the script! I grabbed it immediately! üòÇ\n\n\nüîç **Context**: Due to GPU limitations, I've focused on optimizing a shallow model for best results.\n\n\n\nüõ†Ô∏è **My Setup**:\n1. **LightGBM**: Utilized with nearly 30 handcrafted features to cover most scoring criteria. üìä\n2. **4-Fold Cross-Validation**: Grouped by `prompt_id`. üîÑ\n3. **Optuna**: Conducted 100 trials for all folds. üéØ\n\nüìà **Initial Result**: Achieved a score of approximately 0.51.\n\n\n\nüîÑ **Changes by OLEKSIY**:\n- Scrapped the `prompt_quest` meta-information, leading to significant changes.\n- Grouped by `grade` and used the median instead of the mean. üìù\n\nüìà **Updated Result**: Score improved to 0.49. I'm contemplating strategies to push the limit further. üöÄ\n\n\n\nüëç If you find this insightful, please upvote! üåü\n\n","metadata":{}},{"cell_type":"markdown","source":"# Initization","metadata":{}},{"cell_type":"code","source":"!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"\n#!pip install \"/kaggle/input/pyphen-0100/Pyphen-0.10.0-py3-none-any.whl\"","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:36:41.147461Z","iopub.execute_input":"2023-10-01T11:36:41.149478Z","iopub.status.idle":"2023-10-01T11:37:52.198867Z","shell.execute_reply.started":"2023-10-01T11:36:41.149442Z","shell.execute_reply":"2023-10-01T11:37:52.198014Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=baa1756506121a9560a34bc5d1c0f719c963a68ef342cf0171299c689c66b55f\n  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\nSuccessfully installed autocorrect-2.6.1\nProcessing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\nInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.7.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Meta Data Cleansing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport spacy\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nimport logging\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load Spacy model\nnlp = spacy.load('en_core_web_sm')\n\nclass FeatureEngineering:\n    \n    def __init__(self, df):\n        self.df = df\n        self.df['grade'].fillna(0, inplace=True)  # Fill NA values in 'grade' with 0\n\n    def classify_author(self, author):\n        doc = nlp(author)\n        for ent in doc.ents:\n            if ent.label_ == 'PERSON':\n                return 'person'\n        return 'org'\n\n    def encode_author_type(self):\n        self.df['author_type'] = self.df['author'].apply(self.classify_author)\n        le = LabelEncoder()\n        self.df['author_type'] = le.fit_transform(self.df['author_type'])\n\n    def frequency_encoding(self):\n        logging.info(\"Applying Frequency Encoding on 'author'\")\n        self.df['author_frequency'] = self.df['author'].map(self.df['author'].value_counts())\n\n    def one_hot_encoding(self):\n        logging.info(\"Applying One-Hot Encoding on 'genre'\")\n        onehot_encoder = OneHotEncoder(sparse=False)\n        genre_onehot = onehot_encoder.fit_transform(self.df[['genre']])\n        df_onehot = pd.DataFrame(genre_onehot, columns=onehot_encoder.get_feature_names_out(['genre']))\n        self.df = pd.concat([self.df, df_onehot], axis=1)\n\n    def feature_scaling(self):\n        logging.info(\"Applying Feature Scaling on 'lexile'\")\n        scaler = StandardScaler()\n        self.df['lexile_scaled'] = scaler.fit_transform(self.df[['lexile']])\n\n    def transform(self):\n        self.encode_author_type()\n        self.frequency_encoding()\n#         self.one_hot_encoding()\n        self.feature_scaling()\n        return self.df\n\n# Initialize FeatureEngineering class and apply transformations\nprompt_grade = pd.read_csv(r'/kaggle/input/commonlit-texts/commonlit_texts.csv')\nfeature_engineer = FeatureEngineering(prompt_grade)\ntransformed_df = feature_engineer.transform()\n\n# Display the transformed DataFrame\nprompt_grade = transformed_df","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:37:52.201481Z","iopub.execute_input":"2023-10-01T11:37:52.201755Z","iopub.status.idle":"2023-10-01T11:38:20.586879Z","shell.execute_reply.started":"2023-10-01T11:37:52.201730Z","shell.execute_reply":"2023-10-01T11:38:20.586022Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"keep_columns = ['title','author','description','grade','genre','lexile','lexile_scaled','is_prose','author_type','author_frequency']\nprompt_grade = prompt_grade[keep_columns]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:20.587898Z","iopub.execute_input":"2023-10-01T11:38:20.588424Z","iopub.status.idle":"2023-10-01T11:38:20.595688Z","shell.execute_reply.started":"2023-10-01T11:38:20.588395Z","shell.execute_reply":"2023-10-01T11:38:20.594665Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# prompt_grade = prompt_grade[['title','grade','lexile_md','genre_big_group_encode','author_type']]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:20.598688Z","iopub.execute_input":"2023-10-01T11:38:20.599106Z","iopub.status.idle":"2023-10-01T11:38:20.610137Z","shell.execute_reply.started":"2023-10-01T11:38:20.599068Z","shell.execute_reply":"2023-10-01T11:38:20.609321Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# for _ in list(set(df.author.to_list())):\n#     print(_)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:20.611500Z","iopub.execute_input":"2023-10-01T11:38:20.611763Z","iopub.status.idle":"2023-10-01T11:38:20.621986Z","shell.execute_reply.started":"2023-10-01T11:38:20.611740Z","shell.execute_reply":"2023-10-01T11:38:20.621217Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"from typing import List\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport logging\nimport os\nimport shutil\nimport json\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset,load_dataset, load_from_disk\nfrom transformers import TrainingArguments, Trainer\nfrom datasets import load_metric, disable_progress_bar\nfrom sklearn.metrics import mean_squared_error\nimport torch\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom textblob import TextBlob\nimport optuna\nimport optuna.integration.lightgbm as lgb\n#import pyphen\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom collections import Counter\nfrom nltk import ne_chunk, word_tokenize, pos_tag\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nimport spacy\nimport re\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\nimport lightgbm as lgb\n\nwarnings.simplefilter(\"ignore\")\nlogging.disable(logging.ERROR)\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ndisable_progress_bar()\ntqdm.pandas()\n\ndef seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:20.623461Z","iopub.execute_input":"2023-10-01T11:38:20.624348Z","iopub.status.idle":"2023-10-01T11:38:25.680701Z","shell.execute_reply.started":"2023-10-01T11:38:20.624304Z","shell.execute_reply":"2023-10-01T11:38:25.680023Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    model_name=\"debertav3base\"\n    learning_rate=1.5e-5\n    weight_decay=0.02\n    hidden_dropout_prob=0.007\n    attention_probs_dropout_prob=0.007\n    num_train_epochs=5\n    n_splits=4\n    batch_size=12\n    random_seed=42\n    save_steps=100\n    max_length=512\n    adjustment_factor= 0.5 ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:25.681674Z","iopub.execute_input":"2023-10-01T11:38:25.682082Z","iopub.status.idle":"2023-10-01T11:38:25.686775Z","shell.execute_reply.started":"2023-10-01T11:38:25.682053Z","shell.execute_reply":"2023-10-01T11:38:25.685963Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Joining prmpt and meta data ","metadata":{}},{"cell_type":"code","source":"def preprocess_and_join(df1, df2, df1_title_col, df2_title_col, grade_col):\n    # Copy dataframes to avoid modifying the originals\n    df1 = df1.copy()\n    df2 = df2.copy()\n\n    # Preprocess titles\n    df1[df1_title_col] = df1[df1_title_col].str.replace('\"', '').str.strip()\n    df2[df2_title_col] = df2[df2_title_col].str.replace('\"', '').str.strip()\n\n    # Remove duplicate grades\n    df2 = df2.drop_duplicates(subset=df2_title_col, keep='first')\n\n    # Join dataframes\n    merged_df = df1.merge(df2, how='left', left_on=df1_title_col, right_on=df2_title_col)\n    \n\n    # Postprocess grades\n    merged_df[grade_col] = merged_df[grade_col].fillna(0)\n    merged_df[grade_col] = merged_df[grade_col].astype(int).astype('category')\n\n \n    return merged_df\n\n# Usage\nDATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\nprompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\nprompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\nsummaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\nsummaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\nsample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n# prompt_grade = pd.read_csv(r'/kaggle/input/litess-titles/all_titles.csv')\nprompts_train = preprocess_and_join(prompts_train, prompt_grade, 'prompt_title', 'title', 'grade')\nprompts_test = preprocess_and_join(prompts_test, prompt_grade, 'prompt_title', 'title', 'grade')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:25.688371Z","iopub.execute_input":"2023-10-01T11:38:25.688771Z","iopub.status.idle":"2023-10-01T11:38:25.845295Z","shell.execute_reply.started":"2023-10-01T11:38:25.688734Z","shell.execute_reply":"2023-10-01T11:38:25.844302Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"prompts_train","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:25.846581Z","iopub.execute_input":"2023-10-01T11:38:25.846875Z","iopub.status.idle":"2023-10-01T11:38:25.868400Z","shell.execute_reply.started":"2023-10-01T11:38:25.846848Z","shell.execute_reply":"2023-10-01T11:38:25.867579Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   \n1    3b9047  In complete sentences, summarize the structure...   \n2    814d6b  Summarize how the Third Wave developed over su...   \n3    ebad26  Summarize the various ways the factory would u...   \n\n                prompt_title  \\\n0                 On Tragedy   \n1  Egyptian Social Structure   \n2             The Third Wave   \n3    Excerpt from The Jungle   \n\n                                         prompt_text  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n1  Egyptian society was structured like a pyramid...   \n2  Background \\r\\nThe Third Wave experiment took ...   \n3  With one member trimming beef in a cannery, an...   \n\n                       title           author  \\\n0                 On Tragedy        Aristotle   \n1  Egyptian Social Structure    USHistory.org   \n2             The Third Wave  CommonLit Staff   \n3    Excerpt from The Jungle   Upton Sinclair   \n\n                                         description grade  \\\n0  This excerpt from Aristotle's famous work \"Poe...     9   \n1  This informational text describes the social s...     7   \n2  In 1967, a history teacher's social experiment...     9   \n3  In this disturbing piece of political fiction,...    11   \n\n                genre  lexile  lexile_scaled  is_prose  author_type  \\\n0          Philosophy  1070.0       0.341991         1            1   \n1  Informational Text   890.0      -0.387469         1            0   \n2  Informational Text  1260.0       1.111977         1            0   \n3   Fiction - General  1400.0       1.679335         1            0   \n\n   author_frequency  \n0                 2  \n1                42  \n2                24  \n3                 1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>title</th>\n      <th>author</th>\n      <th>description</th>\n      <th>grade</th>\n      <th>genre</th>\n      <th>lexile</th>\n      <th>lexile_scaled</th>\n      <th>is_prose</th>\n      <th>author_type</th>\n      <th>author_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>On Tragedy</td>\n      <td>Aristotle</td>\n      <td>This excerpt from Aristotle's famous work \"Poe...</td>\n      <td>9</td>\n      <td>Philosophy</td>\n      <td>1070.0</td>\n      <td>0.341991</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>Egyptian Social Structure</td>\n      <td>USHistory.org</td>\n      <td>This informational text describes the social s...</td>\n      <td>7</td>\n      <td>Informational Text</td>\n      <td>890.0</td>\n      <td>-0.387469</td>\n      <td>1</td>\n      <td>0</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>814d6b</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>The Third Wave</td>\n      <td>CommonLit Staff</td>\n      <td>In 1967, a history teacher's social experiment...</td>\n      <td>9</td>\n      <td>Informational Text</td>\n      <td>1260.0</td>\n      <td>1.111977</td>\n      <td>1</td>\n      <td>0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>Upton Sinclair</td>\n      <td>In this disturbing piece of political fiction,...</td>\n      <td>11</td>\n      <td>Fiction - General</td>\n      <td>1400.0</td>\n      <td>1.679335</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompts_test","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:25.872902Z","iopub.execute_input":"2023-10-01T11:38:25.873321Z","iopub.status.idle":"2023-10-01T11:38:25.887599Z","shell.execute_reply.started":"2023-10-01T11:38:25.873292Z","shell.execute_reply":"2023-10-01T11:38:25.886378Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  prompt_id prompt_question     prompt_title       prompt_text title author  \\\n0    abc123    Summarize...  Example Title 1  Heading\\nText...   NaN    NaN   \n1    def789    Summarize...  Example Title 2  Heading\\nText...   NaN    NaN   \n\n  description grade genre  lexile  lexile_scaled  is_prose  author_type  \\\n0         NaN     0   NaN     NaN            NaN       NaN          NaN   \n1         NaN     0   NaN     NaN            NaN       NaN          NaN   \n\n   author_frequency  \n0               NaN  \n1               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>title</th>\n      <th>author</th>\n      <th>description</th>\n      <th>grade</th>\n      <th>genre</th>\n      <th>lexile</th>\n      <th>lexile_scaled</th>\n      <th>is_prose</th>\n      <th>author_type</th>\n      <th>author_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc123</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>def789</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Documentation for Text Preprocessing Function `run`\n\n## Overview\n\nThe `run` function is a comprehensive text preprocessing pipeline designed to prepare and enrich text data for further analysis or machine learning tasks. The function takes in two data frames, `prompts` and `summaries`, along with a `mode` parameter, and returns a processed data frame with various linguistic and statistical features.\n\n---\n\n## Parameters\n\n- **prompts: pd.DataFrame**  \n  - A DataFrame containing the prompts with a column named `prompt_text`.\n\n- **summaries: pd.DataFrame**  \n  - A DataFrame containing the summaries with a column named `text`.\n\n- **mode: str**  \n  - The mode in which the function operates, although its specific use is not detailed in the code snippet.\n\n---\n\n## Features Grouped by Cognitive or Exam Criteria\n\n### Text Length and Tokenization\n\n- `prompt_length`: Length of the prompt in terms of tokens.\n- `summary_length`: Length of the summary in terms of tokens.\n- `prompt_tokens`: Tokenized form of the prompt.\n- `summary_tokens`: Tokenized form of the summary.\n\n### Spelling and Grammar\n\n- `splling_err_num`: Number of spelling errors in the summary.\n- `gunning_fog`, `flesch_kincaid_grade_level`, `flesch_reading_ease`: Readability scores for both prompts and summaries.\n\n### Linguistic Features\n\n- `word_count`, `sentence_length`, `vocabulary_richness`: Basic text statistics.\n- `avg_word_length`, `comma_count`, `semicolon_count`: Additional linguistic features.\n- `pos_ratios`: Part-of-speech ratios in the text.\n- `punctuation_ratios`: Punctuation ratios in the text.\n\n### Text Similarity and Overlap\n\n- `word_overlap_count`, `bigram_overlap_count`, `trigram_overlap_count`: N-gram overlaps between prompts and summaries.\n- `jaccard_similarity`: Jaccard similarity between prompts and summaries.\n- `text_similarity`: Custom text similarity metric.\n\n### Sentiment Analysis\n\n- `sentiment_polarity`, `sentiment_subjectivity`: Sentiment scores.\n- `sentiment_scores`: Detailed sentiment scores, further decomposed into individual columns.\n\n","metadata":{}},{"cell_type":"code","source":"#dic = pyphen.Pyphen(lang='en')\nsid = SentimentIntensityAnalyzer()\n\nclass Preprocessor:\n    def __init__(self, \n                model_name: str,\n                ) -> None:\n        #self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n        self.twd = TreebankWordDetokenizer()\n        self.STOP_WORDS = set(stopwords.words('english'))\n        \n        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n        self.speller = Speller(lang='en')\n        self.spellchecker = SpellChecker() \n        \n    def calculate_text_similarity(self, row):\n        vectorizer = TfidfVectorizer()\n        tfidf_matrix = vectorizer.fit_transform([row['prompt_text'], row['text']])\n        return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]).flatten()[0]\n    \n    def sentiment_analysis(self, text):\n        analysis = TextBlob(text)\n        return analysis.sentiment.polarity, analysis.sentiment.subjectivity\n    \n    def word_overlap_count(self, row):\n        \"\"\" intersection(prompt_text, text) \"\"\"        \n        def check_is_stop_word(word):\n            return word in self.STOP_WORDS\n        \n        prompt_words = row['prompt_tokens']\n        summary_words = row['summary_tokens']\n        if self.STOP_WORDS:\n            prompt_words = list(filter(check_is_stop_word, prompt_words))\n            summary_words = list(filter(check_is_stop_word, summary_words))\n        return len(set(prompt_words).intersection(set(summary_words)))\n            \n    def ngrams(self, token, n):\n        # Use the zip function to help us generate n-grams\n        # Concatentate the tokens into ngrams and return\n        ngrams = zip(*[token[i:] for i in range(n)])\n        return [\" \".join(ngram) for ngram in ngrams]\n\n    def ngram_co_occurrence(self, row, n: int) -> int:\n        # Tokenize the original text and summary into words\n        original_tokens = row['prompt_tokens']\n        summary_tokens = row['summary_tokens']\n\n        # Generate n-grams for the original text and summary\n        original_ngrams = set(self.ngrams(original_tokens, n))\n        summary_ngrams = set(self.ngrams(summary_tokens, n))\n\n        # Calculate the number of common n-grams\n        common_ngrams = original_ngrams.intersection(summary_ngrams)\n        return len(common_ngrams)\n    \n    def ner_overlap_count(self, row, mode:str):\n        model = self.spacy_ner_model\n        def clean_ners(ner_list):\n            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n        prompt = model(row['prompt_text'])\n        summary = model(row['text'])\n\n        if \"spacy\" in str(model):\n            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n        elif \"stanza\" in str(model):\n            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n            summary_ner = set([(token.text, token.type) for token in summary.ents])\n        else:\n            raise Exception(\"Model not supported\")\n\n        prompt_ner = clean_ners(prompt_ner)\n        summary_ner = clean_ners(summary_ner)\n\n        intersecting_ners = prompt_ner.intersection(summary_ner)\n        \n        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n        \n        if mode == \"train\":\n            return ner_dict\n        elif mode == \"test\":\n            return {key: ner_dict.get(key) for key in self.ner_keys}\n\n    \n    def quotes_count(self, row):\n        summary = row['text']\n        text = row['prompt_text']\n        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n        if len(quotes_from_summary)>0:\n            return [quote in text for quote in quotes_from_summary].count(True)\n        else:\n            return 0\n\n    def spelling(self, text):\n        \n        wordlist=text.split()\n        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n\n        return amount_miss\n    \n    def calculate_unique_words(self,text):\n        unique_words = set(text.split())\n        return len(unique_words)\n    \n    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n        self.spellchecker.word_frequency.load_words(tokens)\n        self.speller.nlp_data.update({token:1000 for token in tokens})\n        \n    def calculate_pos_ratios(self , text):\n        pos_tags = pos_tag(nltk.word_tokenize(text))\n        pos_counts = Counter(tag for word, tag in pos_tags)\n        total_words = len(pos_tags)\n        ratios = {tag: count / total_words for tag, count in pos_counts.items()}\n        return ratios\n    \n    def calculate_punctuation_ratios(self,text):\n        total_chars = len(text)\n        punctuation_counts = Counter(char for char in text if char in '.,!?;:\"()[]{}')\n        ratios = {char: count / total_chars for char, count in punctuation_counts.items()}\n        return ratios\n    \n    def calculate_keyword_density(self,row):\n        keywords = set(row['prompt_text'].split())\n        text_words = row['text'].split()\n        keyword_count = sum(1 for word in text_words if word in keywords)\n        return keyword_count / len(text_words)\n    \n    def count_syllables(self,word):\n        word = word.lower()\n        vowels = \"aeiouy\"\n        count = 0\n        count += sum(1 for letter in word if letter in vowels)\n        if word.endswith('e'):\n            count -= 1\n        count -= sum(word.count(diph) for diph in ['oi', 'oy', 'ou', 'ow', 'au', 'aw', 'oo', 'ee', 'ea', 'ie', 'ei', 'ai', 'ay', 'ey', 'ua', 'ue', 'ui'])\n        for i in range(1, len(word) - 1):\n            if word[i] not in vowels and word[i-1] in vowels and word[i+1] in vowels:\n                count += 1\n        count = max(1, count)\n        return count\n\n    def flesch_reading_ease_manual(self,text):\n        total_sentences = len(TextBlob(text).sentences)\n        total_words = len(TextBlob(text).words)\n        total_syllables = sum(self.count_syllables(word) for word in TextBlob(text).words)\n\n        if total_sentences == 0 or total_words == 0:\n            return 0\n\n        flesch_score = 206.835 - 1.015 * (total_words / total_sentences) - 84.6 * (total_syllables / total_words)\n        return flesch_score\n    \n    def flesch_kincaid_grade_level(self, text):\n        total_sentences = len(TextBlob(text).sentences)\n        total_words = len(TextBlob(text).words)\n        total_syllables = sum(self.count_syllables(word) for word in TextBlob(text).words)\n\n        if total_sentences == 0 or total_words == 0:\n            return 0\n\n        fk_grade = 0.39 * (total_words / total_sentences) + 11.8 * (total_syllables / total_words) - 15.59\n        return fk_grade\n    \n    def gunning_fog(self, text):\n        total_sentences = len(TextBlob(text).sentences)\n        total_words = len(TextBlob(text).words)\n        complex_words = sum(1 for word in TextBlob(text).words if self.count_syllables(word) > 2)\n\n        if total_sentences == 0 or total_words == 0:\n            return 0\n\n        fog_index = 0.4 * ((total_words / total_sentences) + 100 * (complex_words / total_words))\n        return fog_index\n    \n    def calculate_sentiment_scores(self,text):\n        sentiment_scores = sid.polarity_scores(text)\n        return sentiment_scores\n    \n    def count_difficult_words(self, text, syllable_threshold=3):\n        words = TextBlob(text).words\n        difficult_words_count = sum(1 for word in words if self.count_syllables(word) >= syllable_threshold)\n        return difficult_words_count\n\n\n    \n    def run(self, \n            prompts: pd.DataFrame,\n            summaries:pd.DataFrame,\n            mode:str\n        ) -> pd.DataFrame:\n        \n        # before merge preprocess\n        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].progress_apply(\n            lambda x: len(word_tokenize(x))\n        )\n        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].progress_apply(\n            lambda x: word_tokenize(x)\n        )\n\n        summaries[\"summary_length\"] = summaries[\"text\"].progress_apply(\n            lambda x: len(word_tokenize(x))\n        )\n        summaries[\"summary_tokens\"] = summaries[\"text\"].progress_apply(\n            lambda x: word_tokenize(x)\n        )\n        \n        # Add prompt tokens into spelling checker dictionary\n        prompts[\"prompt_tokens\"].progress_apply(\n            lambda x: self.add_spelling_dictionary(x)\n        )\n        \n        prompts['gunning_fog_prompt'] = prompts['prompt_text'].progress_apply(self.gunning_fog)\n        prompts['flesch_kincaid_grade_level_prompt'] = prompts['prompt_text'].progress_apply(self.flesch_kincaid_grade_level)\n        prompts['flesch_reading_ease_prompt'] = prompts['prompt_text'].progress_apply(self.flesch_reading_ease_manual)\n\n        \n#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n        # fix misspelling\n#         summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n#             lambda x: self.speller(x)\n#         )\n        \n        \n        # count misspelling\n        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n        \n        # merge prompts and summaries\n        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n        input_df['flesch_reading_ease'] = input_df['text'].progress_apply(self.flesch_reading_ease_manual)\n        input_df['word_count'] = input_df['text'].progress_apply(lambda x: len(x.split()))\n        input_df['sentence_length'] = input_df['text'].progress_apply(lambda x: len(x.split('.')))\n        input_df['vocabulary_richness'] = input_df['text'].progress_apply(lambda x: len(set(x.split())))\n\n        input_df['word_count2'] = [len(t.split(' ')) for t in input_df.text]\n        input_df['num_unq_words']=[len(list(set(x.lower().split(' ')))) for x in input_df.text]\n        input_df['num_chars']= [len(x) for x in input_df.text]\n\n        # Additional features\n        input_df['avg_word_length'] = input_df['text'].progress_apply(lambda x: np.mean([len(word) for word in x.split()]))\n        input_df['comma_count'] = input_df['text'].progress_apply(lambda x: x.count(','))\n        input_df['semicolon_count'] = input_df['text'].progress_apply(lambda x: x.count(';'))\n\n        # after merge preprocess\n        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n        \n        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n        input_df['bigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence,args=(2,), axis=1 \n        )\n        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n        \n        input_df['trigram_overlap_count'] = input_df.progress_apply(\n            self.ngram_co_occurrence, args=(3,), axis=1\n        )\n        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n        \n        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n        \n        input_df['exclamation_count'] = input_df['text'].progress_apply(lambda x: x.count('!'))\n        input_df['question_count'] = input_df['text'].progress_apply(lambda x: x.count('?'))\n        input_df['pos_ratios'] = input_df['text'].progress_apply(self.calculate_pos_ratios)\n\n        # Convert the dictionary of POS ratios into a single value (mean)\n        input_df['pos_mean'] = input_df['pos_ratios'].progress_apply(lambda x: np.mean(list(x.values())))\n        input_df['punctuation_ratios'] = input_df['text'].progress_apply(self.calculate_punctuation_ratios)\n\n        # Convert the dictionary of punctuation ratios into a single value (sum)\n        input_df['punctuation_sum'] = input_df['punctuation_ratios'].progress_apply(lambda x: np.sum(list(x.values())))\n        input_df['keyword_density'] = input_df.progress_apply(self.calculate_keyword_density, axis=1)\n        input_df['jaccard_similarity'] = input_df.progress_apply(lambda row: len(set(word_tokenize(row['prompt_text'])) & set(word_tokenize(row['text']))) / len(set(word_tokenize(row['prompt_text'])) | set(word_tokenize(row['text']))), axis=1)\n        tqdm.pandas(desc=\"Performing Sentiment Analysis\")\n        input_df[['sentiment_polarity', 'sentiment_subjectivity']] = input_df['text'].progress_apply(\n            lambda x: pd.Series(self.sentiment_analysis(x))\n        )\n        tqdm.pandas(desc=\"Calculating Text Similarity\")\n        input_df['text_similarity'] = input_df.progress_apply(self.calculate_text_similarity, axis=1)\n        #Calculate sentiment scores for each row\n        input_df['sentiment_scores'] = input_df['text'].progress_apply(self.calculate_sentiment_scores)\n        \n        input_df['gunning_fog'] = input_df['text'].progress_apply(self.gunning_fog)\n        input_df['flesch_kincaid_grade_level'] = input_df['text'].progress_apply(self.flesch_kincaid_grade_level)\n        input_df['count_difficult_words'] = input_df['text'].progress_apply(self.count_difficult_words)\n\n        # Convert sentiment_scores into individual columns\n        sentiment_columns = pd.DataFrame(list(input_df['sentiment_scores']))\n        input_df = pd.concat([input_df, sentiment_columns], axis=1)\n        input_df['sentiment_scores_prompt'] = input_df['prompt_text'].progress_apply(self.calculate_sentiment_scores)\n        # Convert sentiment_scores_prompt into individual columns\n        sentiment_columns_prompt = pd.DataFrame(list(input_df['sentiment_scores_prompt']))\n        sentiment_columns_prompt.columns = [col +'_prompt' for col in sentiment_columns_prompt.columns]\n        input_df = pd.concat([input_df, sentiment_columns_prompt], axis=1)\n        columns =  ['pos_ratios', 'sentiment_scores', 'punctuation_ratios', 'sentiment_scores_prompt']\n        cols_to_drop = [col for col in columns if col in input_df.columns]\n        if cols_to_drop:\n            input_df = input_df.drop(columns=cols_to_drop)\n        \n        print(cols_to_drop)\n        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n    \npreprocessor = Preprocessor(model_name=CFG.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:25.889639Z","iopub.execute_input":"2023-10-01T11:38:25.889920Z","iopub.status.idle":"2023-10-01T11:38:26.891466Z","shell.execute_reply.started":"2023-10-01T11:38:25.889885Z","shell.execute_reply":"2023-10-01T11:38:26.890538Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Group by grade instead of prompt_id","metadata":{}},{"cell_type":"code","source":"train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\ntest = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n\n# Calculate the number of unique groups\nn_unique_groups = train[\"grade\"].nunique()\n\n# Set n_splits to be the smaller of CFG.n_splits and the number of unique groups\nn_splits = min(CFG.n_splits, n_unique_groups)\ngkf = GroupKFold(n_splits=n_splits)\n\nfor i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"grade\"])):\n    train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:38:26.893178Z","iopub.execute_input":"2023-10-01T11:38:26.893695Z","iopub.status.idle":"2023-10-01T11:43:08.337296Z","shell.execute_reply.started":"2023-10-01T11:38:26.893659Z","shell.execute_reply":"2023-10-01T11:43:08.336235Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 119.87it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 197.30it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:04<00:00, 1736.47it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:04<00:00, 1695.51it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 38.82it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 41.33it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 48.60it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 47.99it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:01<00:00, 7155.02it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:17<00:00, 406.63it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 153396.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 434801.69it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 76498.06it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 38481.68it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 444618.19it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 565368.98it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 8309.58it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:01<00:00, 4402.90it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:01<00:00, 3937.99it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 73794.06it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 528659.68it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 550991.68it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:27<00:00, 259.12it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 82808.93it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 45522.31it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 123042.17it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:00<00:00, 7995.94it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [01:19<00:00, 90.64it/s]\nPerforming Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:05<00:00, 1239.79it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:25<00:00, 276.51it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:05<00:00, 1282.04it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:17<00:00, 410.04it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:17<00:00, 408.91it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:09<00:00, 748.47it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7165/7165 [00:58<00:00, 121.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"['pos_ratios', 'sentiment_scores', 'punctuation_ratios', 'sentiment_scores_prompt']\n","output_type":"stream"},{"name":"stderr","text":"Calculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 2286.97it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 2746.76it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 4549.14it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 4819.65it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 38.74it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1367.11it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1522.43it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1607.01it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 8991.01it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2070.49it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 8616.96it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 6288.31it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 7096.96it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 6472.69it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 8073.73it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 7139.24it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1905.20it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1957.44it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 3394.82it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2370.67it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 7316.71it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 6418.22it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 865.03it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 5964.17it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 7887.74it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 7436.71it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 3153.02it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1483.27it/s]\nPerforming Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1617.86it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 259.58it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 5170.17it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1864.55it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2028.44it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2919.30it/s]\nCalculating Text Similarity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 5687.19it/s]","output_type":"stream"},{"name":"stdout","text":"['pos_ratios', 'sentiment_scores', 'punctuation_ratios', 'sentiment_scores_prompt']\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n# test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")\n\n# # Calculate the number of unique groups\n# n_unique_groups = train[\"grade\"].nunique()\n\n# # Set n_splits to be the smaller of CFG.n_splits and the number of unique groups\n# n_splits = min(CFG.n_splits, n_unique_groups)\n# gkf = GroupKFold(n_splits=n_splits)\n\n# for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"grade\"])):\n#     train.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.338471Z","iopub.execute_input":"2023-10-01T11:43:08.338660Z","iopub.status.idle":"2023-10-01T11:43:08.343767Z","shell.execute_reply.started":"2023-10-01T11:43:08.338637Z","shell.execute_reply":"2023-10-01T11:43:08.342751Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"CFG.n_splits = n_splits","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.345162Z","iopub.execute_input":"2023-10-01T11:43:08.345394Z","iopub.status.idle":"2023-10-01T11:43:08.362117Z","shell.execute_reply.started":"2023-10-01T11:43:08.345365Z","shell.execute_reply":"2023-10-01T11:43:08.361022Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.363486Z","iopub.execute_input":"2023-10-01T11:43:08.363713Z","iopub.status.idle":"2023-10-01T11:43:08.397979Z","shell.execute_reply.started":"2023-10-01T11:43:08.363686Z","shell.execute_reply":"2023-10-01T11:43:08.396998Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n\n    content   wording  summary_length  splling_err_num  \\\n0  0.205683  0.380538              64                5   \n1 -0.548304  0.506755              54                2   \n2  3.128928  4.231226             269               32   \n3 -0.210614 -0.471415              28                5   \n4  3.272894  3.219757             232               29   \n\n                                     prompt_question  \\\n0  Summarize how the Third Wave developed over su...   \n1  Summarize the various ways the factory would u...   \n2  In complete sentences, summarize the structure...   \n3  In complete sentences, summarize the structure...   \n4  Summarize how the Third Wave developed over su...   \n\n                prompt_title  \\\n0             The Third Wave   \n1    Excerpt from The Jungle   \n2  Egyptian Social Structure   \n3  Egyptian Social Structure   \n4             The Third Wave   \n\n                                         prompt_text  ...  \\\n0  Background \\r\\nThe Third Wave experiment took ...  ...   \n1  With one member trimming beef in a cannery, an...  ...   \n2  Egyptian society was structured like a pyramid...  ...   \n3  Egyptian society was structured like a pyramid...  ...   \n4  Background \\r\\nThe Third Wave experiment took ...  ...   \n\n  count_difficult_words    neg    neu    pos compound  neg_prompt  neu_prompt  \\\n0                    13  0.033  0.832  0.135   0.7845       0.027       0.873   \n1                     3  0.000  0.946  0.054   0.4310       0.086       0.879   \n2                    52  0.047  0.814  0.139   0.9725       0.063       0.845   \n3                     5  0.000  1.000  0.000   0.0000       0.063       0.845   \n4                    60  0.000  0.896  0.104   0.9696       0.027       0.873   \n\n   pos_prompt  compound_prompt  fold  \n0       0.100           0.9915   0.0  \n1       0.035          -0.9949   2.0  \n2       0.092           0.9283   1.0  \n3       0.092           0.9283   1.0  \n4       0.100           0.9915   0.0  \n\n[5 rows x 62 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>summary_length</th>\n      <th>splling_err_num</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>...</th>\n      <th>count_difficult_words</th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>neg_prompt</th>\n      <th>neu_prompt</th>\n      <th>pos_prompt</th>\n      <th>compound_prompt</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>64</td>\n      <td>5</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>...</td>\n      <td>13</td>\n      <td>0.033</td>\n      <td>0.832</td>\n      <td>0.135</td>\n      <td>0.7845</td>\n      <td>0.027</td>\n      <td>0.873</td>\n      <td>0.100</td>\n      <td>0.9915</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n      <td>54</td>\n      <td>2</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0.000</td>\n      <td>0.946</td>\n      <td>0.054</td>\n      <td>0.4310</td>\n      <td>0.086</td>\n      <td>0.879</td>\n      <td>0.035</td>\n      <td>-0.9949</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n      <td>269</td>\n      <td>32</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>...</td>\n      <td>52</td>\n      <td>0.047</td>\n      <td>0.814</td>\n      <td>0.139</td>\n      <td>0.9725</td>\n      <td>0.063</td>\n      <td>0.845</td>\n      <td>0.092</td>\n      <td>0.9283</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n      <td>28</td>\n      <td>5</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>0.063</td>\n      <td>0.845</td>\n      <td>0.092</td>\n      <td>0.9283</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n      <td>232</td>\n      <td>29</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n      <td>...</td>\n      <td>60</td>\n      <td>0.000</td>\n      <td>0.896</td>\n      <td>0.104</td>\n      <td>0.9696</td>\n      <td>0.027</td>\n      <td>0.873</td>\n      <td>0.100</td>\n      <td>0.9915</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 62 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    rmse = mean_squared_error(labels, predictions, squared=False)\n    return {\"rmse\": rmse}\n\ndef compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }\n\ndef compt_score(content_true, content_pred, wording_true, wording_pred):\n    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n    \n    return (content_score + wording_score)/2","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.399358Z","iopub.execute_input":"2023-10-01T11:43:08.399571Z","iopub.status.idle":"2023-10-01T11:43:08.405495Z","shell.execute_reply.started":"2023-10-01T11:43:08.399548Z","shell.execute_reply":"2023-10-01T11:43:08.404905Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# üìÑ LightGBM Hyperparameter Tuning with Optuna: Professional Documentation\n\n## üéØ Overview\n\nThe script performs hyperparameter optimization for LightGBM using Optuna. It aims to minimize the RMSE (Root Mean Square Error) for a regression task. The script employs k-fold cross-validation and saves the best models for each target.\n\n---\n\n## üõ† Parameters\n\n- **boosting_type**: Gradient Boosting Decision Tree (`gbdt`).\n- **random_state**: Seed for reproducibility (`42`).\n- **objective**: Task objective (`regression`).\n- **metric**: Evaluation metric (`rmse`).\n- **learning_rate**: Learning rate, optimized by Optuna.\n- **max_depth**: Maximum depth of the trees.\n- **lambda_l1, lambda_l2**: L1 and L2 regularization, optimized by Optuna.\n- **num_leaves**: Number of leaves, optimized by Optuna.\n- **verbosity**: Logging level (`-1` to suppress warnings).\n\n---\n\n## üìä Model Training\n\n1. **Initialization**: Create an empty dictionary `model_dict` to store the best models for each target.\n2. **Cross-Validation**: Loop through each fold and split the data into training and validation sets.\n3. **Optimization**: Use Optuna to optimize hyperparameters.\n4. **Model Training**: Train LightGBM models with the optimized parameters.\n5. **Evaluation**: Store the best models and their scores.\n\n---\n\n## üìà Key Functions\n\n- `lgb.train()`: Trains the LightGBM model.\n- `optuna.create_study()`: Creates an Optuna study object.\n- `study.optimize()`: Runs the optimization.\n\n---\n\n## üìã Logging Insights\n\nStructured logs can be incorporated to track the progress of each trial and the best parameters found.\n\n```python\nimport logging\nlogging.info(f\"Best trial: score {study.best_value}, params {study.best_params}\")\n```\n\n---","metadata":{}},{"cell_type":"code","source":"# targets = [\"content\", \"wording\"]\n\n# drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n#                 \"prompt_question\", \"prompt_title\", \n#                 \"prompt_text\",\"title\", \"author\", \"description\", \"genre\"\n#                ] + targets\n\n\n# def identify_invalid_dtype_columns(df, valid_dtypes):\n#     invalid_columns = [col for col in df.columns if df[col].dtype not in valid_dtypes]\n#     if invalid_columns and invalid_columns not in drop_columns:\n#         print(f\"Columns with invalid data types: {invalid_columns}\")\n#     else:\n#         print(\"All columns have valid data types.\")\n\n# # List of valid data types\n# valid_dtypes = [int, float, bool]\n\n# # Run the function to identify columns with unexpected data types\n# identify_invalid_dtype_columns(train, valid_dtypes)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.406936Z","iopub.execute_input":"2023-10-01T11:43:08.407184Z","iopub.status.idle":"2023-10-01T11:43:08.419227Z","shell.execute_reply.started":"2023-10-01T11:43:08.407158Z","shell.execute_reply":"2023-10-01T11:43:08.418293Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"targets = [\"content\", \"wording\"]\n\ndrop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n                \"prompt_question\", \"prompt_title\", \n                \"prompt_text\",\"title\", \"author\", \"description\", \"genre\"\n               ] + targets\n\nN = 10  # Adjust based on preference or observations\nimport optuna\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xgb\ndef objective(trial, X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\n    dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n    dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n    max_depth = trial.suggest_int('max_depth', 9, 20)\n    params = {\n        'boosting_type': 'gbdt',\n        'random_state': 42,\n        'objective': 'regression',\n        'metric': 'rmse',\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n        'max_depth': max_depth,\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 10),\n        'verbosity': -3  # Add this line to suppress warnings and info messages\n\n    }\n\n    evaluation_results = {}\n    model = lgb.train(params,\n                      num_boost_round=10000,\n                      valid_names=['train', 'valid'],\n                      train_set=dtrain,\n                      valid_sets=dval,\n                      verbose_eval=1000,\n                      early_stopping_rounds=30,\n                      callbacks=[lgb.record_evaluation(evaluation_results)])\n\n    # Use the last metric for early stopping\n    evals_result = model.best_score\n    last_metric = list(evals_result.values())[-1]\n    trial.set_user_attr('best_model', model)  # Save the model in the trial\n    return last_metric[list(last_metric.keys())[-1]]\n\nmodel_dict = {\n    \"content\": {\n        \"main_models\": [],\n        \"post_models\": [],\n        \"top_features\": []\n    },\n    \"wording\": {\n        \"main_models\": [],\n        \"post_models\": [],\n        \"top_features\": []\n    }\n}\n\nfor target in targets:\n    models = []\n    \n    for fold in range(CFG.n_splits):\n        print(f'For {target} and fold {fold}')\n        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n        y_train_cv = train[train[\"fold\"] != fold][target]\n\n        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n        y_eval_cv = train[train[\"fold\"] == fold][target]\n\n        study = optuna.create_study(direction='minimize')\n        study.optimize(lambda trial: objective(trial, X_train_cv, y_train_cv, X_eval_cv, y_eval_cv), n_trials=100)\n        \n        print('Best trial: score {}, params {}'.format(study.best_value, study.best_params))\n\n        best_model = study.trials[study.best_trial.number].user_attrs['best_model']\n        model_dict[target][\"main_models\"].append(best_model)\n        \n        y_pred_val = best_model.predict(X_eval_cv)\n        residuals_val = y_eval_cv - y_pred_val\n        \n        correlations = X_eval_cv.corrwith(pd.Series(residuals_val))\n        top_features = correlations.abs().sort_values(ascending=False).head(N).index\n        \n        xgb_reg = xgb.XGBRegressor(learning_rate=0.01, max_depth =3,min_child_weight=1, gamma = 0, subsample=0.6, n_estimators=1000,objective=\"reg:squarederror\", booster= \"gbtree\"  )\n        xgb_reg.fit(X_eval_cv[top_features],residuals_val)\n        model_dict[target][\"post_models\"].append(xgb_reg)\n        model_dict[target][\"top_features\"].append(top_features)\n#     model_dict[target] = models","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:43:08.420708Z","iopub.execute_input":"2023-10-01T11:43:08.421042Z","iopub.status.idle":"2023-10-01T11:47:13.631499Z","shell.execute_reply.started":"2023-10-01T11:43:08.421013Z","shell.execute_reply":"2023-10-01T11:47:13.630779Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"For content and fold 0\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[910]\ttrain's rmse: 0.466484\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[312]\ttrain's rmse: 0.465688\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[251]\ttrain's rmse: 0.4682\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.494725\n[2000]\ttrain's rmse: 0.479097\n[3000]\ttrain's rmse: 0.471811\n[4000]\ttrain's rmse: 0.468214\n[5000]\ttrain's rmse: 0.465933\n[6000]\ttrain's rmse: 0.464563\n[7000]\ttrain's rmse: 0.463653\nEarly stopping, best iteration is:\n[7087]\ttrain's rmse: 0.463564\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[165]\ttrain's rmse: 0.465389\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[293]\ttrain's rmse: 0.466204\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[129]\ttrain's rmse: 0.465042\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[691]\ttrain's rmse: 0.46211\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[602]\ttrain's rmse: 0.468801\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[366]\ttrain's rmse: 0.467014\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[562]\ttrain's rmse: 0.473673\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.482157\n[2000]\ttrain's rmse: 0.46941\n[3000]\ttrain's rmse: 0.464886\nEarly stopping, best iteration is:\n[3609]\ttrain's rmse: 0.463444\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.464611\nEarly stopping, best iteration is:\n[1844]\ttrain's rmse: 0.45554\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[773]\ttrain's rmse: 0.464784\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[413]\ttrain's rmse: 0.469607\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[416]\ttrain's rmse: 0.465128\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.484491\n[2000]\ttrain's rmse: 0.468596\nEarly stopping, best iteration is:\n[2719]\ttrain's rmse: 0.464481\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[431]\ttrain's rmse: 0.465894\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.468615\nEarly stopping, best iteration is:\n[1067]\ttrain's rmse: 0.467809\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[600]\ttrain's rmse: 0.454488\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[342]\ttrain's rmse: 0.454825\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[486]\ttrain's rmse: 0.450507\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[279]\ttrain's rmse: 0.459565\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[366]\ttrain's rmse: 0.450577\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[169]\ttrain's rmse: 0.464867\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[199]\ttrain's rmse: 0.464121\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[200]\ttrain's rmse: 0.466573\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[434]\ttrain's rmse: 0.459215\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[470]\ttrain's rmse: 0.452121\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[225]\ttrain's rmse: 0.456054\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[300]\ttrain's rmse: 0.459899\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[448]\ttrain's rmse: 0.454961\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[322]\ttrain's rmse: 0.46895\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[240]\ttrain's rmse: 0.460225\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[524]\ttrain's rmse: 0.454267\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[269]\ttrain's rmse: 0.466431\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[109]\ttrain's rmse: 0.466567\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[315]\ttrain's rmse: 0.463717\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[247]\ttrain's rmse: 0.45726\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[368]\ttrain's rmse: 0.462632\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[407]\ttrain's rmse: 0.454536\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[620]\ttrain's rmse: 0.453574\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[248]\ttrain's rmse: 0.46394\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[476]\ttrain's rmse: 0.45439\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[581]\ttrain's rmse: 0.454516\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[258]\ttrain's rmse: 0.465156\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[282]\ttrain's rmse: 0.462457\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[269]\ttrain's rmse: 0.461352\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[353]\ttrain's rmse: 0.456145\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[303]\ttrain's rmse: 0.464976\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[562]\ttrain's rmse: 0.454814\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[502]\ttrain's rmse: 0.454748\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[362]\ttrain's rmse: 0.46267\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[241]\ttrain's rmse: 0.463944\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[550]\ttrain's rmse: 0.454708\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[383]\ttrain's rmse: 0.454751\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[248]\ttrain's rmse: 0.46766\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[393]\ttrain's rmse: 0.466322\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[480]\ttrain's rmse: 0.452684\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[412]\ttrain's rmse: 0.452606\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[120]\ttrain's rmse: 0.469159\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[316]\ttrain's rmse: 0.455371\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[358]\ttrain's rmse: 0.455069\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[420]\ttrain's rmse: 0.455407\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[414]\ttrain's rmse: 0.453852\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[288]\ttrain's rmse: 0.454007\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[357]\ttrain's rmse: 0.457326\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[218]\ttrain's rmse: 0.461206\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[137]\ttrain's rmse: 0.463665\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[445]\ttrain's rmse: 0.45479\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[275]\ttrain's rmse: 0.463414\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[349]\ttrain's rmse: 0.452929\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[271]\ttrain's rmse: 0.458344\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[282]\ttrain's rmse: 0.457954\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[316]\ttrain's rmse: 0.455748\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[381]\ttrain's rmse: 0.450468\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[346]\ttrain's rmse: 0.454757\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[298]\ttrain's rmse: 0.457635\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[158]\ttrain's rmse: 0.465002\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[344]\ttrain's rmse: 0.453733\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[213]\ttrain's rmse: 0.462402\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[254]\ttrain's rmse: 0.455154\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[292]\ttrain's rmse: 0.455818\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[370]\ttrain's rmse: 0.450075\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[418]\ttrain's rmse: 0.45078\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[246]\ttrain's rmse: 0.466915\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[410]\ttrain's rmse: 0.453529\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[294]\ttrain's rmse: 0.457122\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[161]\ttrain's rmse: 0.467273\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[124]\ttrain's rmse: 0.474084\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.468372\nEarly stopping, best iteration is:\n[1666]\ttrain's rmse: 0.462229\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[422]\ttrain's rmse: 0.454525\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[453]\ttrain's rmse: 0.4543\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[375]\ttrain's rmse: 0.453567\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.4666\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[491]\ttrain's rmse: 0.451285\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[308]\ttrain's rmse: 0.452914\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[312]\ttrain's rmse: 0.457561\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[212]\ttrain's rmse: 0.460363\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[249]\ttrain's rmse: 0.460314\nBest trial: score 0.45007520745807506, params {'max_depth': 10, 'learning_rate': 0.06918420345716408, 'lambda_l1': 9.528175380822404, 'lambda_l2': 0.00039669264166867195, 'num_leaves': 10}\nFor content and fold 1\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[345]\ttrain's rmse: 0.569743\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[115]\ttrain's rmse: 0.567167\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[40]\ttrain's rmse: 0.552304\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[33]\ttrain's rmse: 0.548096\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[101]\ttrain's rmse: 0.56697\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[67]\ttrain's rmse: 0.544794\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[35]\ttrain's rmse: 0.544642\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[67]\ttrain's rmse: 0.549151\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.548116\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[38]\ttrain's rmse: 0.550132\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[28]\ttrain's rmse: 0.54776\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[60]\ttrain's rmse: 0.543699\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[36]\ttrain's rmse: 0.545899\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[32]\ttrain's rmse: 0.558495\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[78]\ttrain's rmse: 0.557428\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[30]\ttrain's rmse: 0.546092\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[76]\ttrain's rmse: 0.555555\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[28]\ttrain's rmse: 0.54924\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[34]\ttrain's rmse: 0.545083\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[98]\ttrain's rmse: 0.559505\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[55]\ttrain's rmse: 0.55337\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[80]\ttrain's rmse: 0.544968\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[65]\ttrain's rmse: 0.542878\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[47]\ttrain's rmse: 0.543498\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[60]\ttrain's rmse: 0.543317\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[60]\ttrain's rmse: 0.544509\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[63]\ttrain's rmse: 0.552985\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[96]\ttrain's rmse: 0.543604\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[69]\ttrain's rmse: 0.545716\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[57]\ttrain's rmse: 0.544109\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[157]\ttrain's rmse: 0.56369\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[79]\ttrain's rmse: 0.543353\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[103]\ttrain's rmse: 0.545455\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[124]\ttrain's rmse: 0.542194\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[815]\ttrain's rmse: 0.569236\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[144]\ttrain's rmse: 0.548394\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[241]\ttrain's rmse: 0.544347\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[119]\ttrain's rmse: 0.542588\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[111]\ttrain's rmse: 0.544643\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[79]\ttrain's rmse: 0.552086\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[135]\ttrain's rmse: 0.548711\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[79]\ttrain's rmse: 0.543845\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[111]\ttrain's rmse: 0.545055\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[62]\ttrain's rmse: 0.544733\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[108]\ttrain's rmse: 0.5433\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[72]\ttrain's rmse: 0.542279\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[71]\ttrain's rmse: 0.54501\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[156]\ttrain's rmse: 0.548046\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[105]\ttrain's rmse: 0.542023\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[77]\ttrain's rmse: 0.549307\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[104]\ttrain's rmse: 0.543541\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[99]\ttrain's rmse: 0.542911\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[102]\ttrain's rmse: 0.543755\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[130]\ttrain's rmse: 0.542489\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[126]\ttrain's rmse: 0.542882\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[155]\ttrain's rmse: 0.543905\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[143]\ttrain's rmse: 0.543567\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[74]\ttrain's rmse: 0.54546\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[62]\ttrain's rmse: 0.543454\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[150]\ttrain's rmse: 0.541963\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[404]\ttrain's rmse: 0.558548\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[186]\ttrain's rmse: 0.542794\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[176]\ttrain's rmse: 0.543047\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[175]\ttrain's rmse: 0.544512\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[137]\ttrain's rmse: 0.542232\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[134]\ttrain's rmse: 0.543284\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[96]\ttrain's rmse: 0.543516\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[131]\ttrain's rmse: 0.544577\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[150]\ttrain's rmse: 0.545519\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[91]\ttrain's rmse: 0.542222\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[86]\ttrain's rmse: 0.542571\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[82]\ttrain's rmse: 0.54242\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[110]\ttrain's rmse: 0.542178\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[103]\ttrain's rmse: 0.541873\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[209]\ttrain's rmse: 0.544667\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[273]\ttrain's rmse: 0.564385\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[137]\ttrain's rmse: 0.542681\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[224]\ttrain's rmse: 0.56292\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.544802\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[221]\ttrain's rmse: 0.542579\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[98]\ttrain's rmse: 0.542194\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[101]\ttrain's rmse: 0.542488\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[99]\ttrain's rmse: 0.543255\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[109]\ttrain's rmse: 0.542363\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[101]\ttrain's rmse: 0.542525\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[98]\ttrain's rmse: 0.542952\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[132]\ttrain's rmse: 0.543403\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[197]\ttrain's rmse: 0.544959\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[114]\ttrain's rmse: 0.556463\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[92]\ttrain's rmse: 0.543335\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[147]\ttrain's rmse: 0.54311\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[108]\ttrain's rmse: 0.542361\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[99]\ttrain's rmse: 0.542908\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[120]\ttrain's rmse: 0.541806\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[126]\ttrain's rmse: 0.542977\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[106]\ttrain's rmse: 0.543364\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[144]\ttrain's rmse: 0.542267\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[163]\ttrain's rmse: 0.542327\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[150]\ttrain's rmse: 0.54273\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[214]\ttrain's rmse: 0.544145\nBest trial: score 0.5418058304496829, params {'max_depth': 18, 'learning_rate': 0.019024127986877602, 'lambda_l1': 3.975053608404276e-06, 'lambda_l2': 0.0008936000328881769, 'num_leaves': 10}\nFor content and fold 2\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[50]\ttrain's rmse: 0.437844\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[41]\ttrain's rmse: 0.439106\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[378]\ttrain's rmse: 0.437201\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[144]\ttrain's rmse: 0.448017\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[147]\ttrain's rmse: 0.436813\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[76]\ttrain's rmse: 0.43742\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[42]\ttrain's rmse: 0.435625\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[249]\ttrain's rmse: 0.434703\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[59]\ttrain's rmse: 0.436631\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[160]\ttrain's rmse: 0.447027\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[84]\ttrain's rmse: 0.438279\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[36]\ttrain's rmse: 0.44228\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[95]\ttrain's rmse: 0.436902\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[91]\ttrain's rmse: 0.435821\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[70]\ttrain's rmse: 0.441191\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[155]\ttrain's rmse: 0.43626\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[64]\ttrain's rmse: 0.438285\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[43]\ttrain's rmse: 0.437212\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[338]\ttrain's rmse: 0.436199\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[38]\ttrain's rmse: 0.439744\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[129]\ttrain's rmse: 0.437793\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[99]\ttrain's rmse: 0.438418\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[116]\ttrain's rmse: 0.437317\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[188]\ttrain's rmse: 0.437367\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[112]\ttrain's rmse: 0.435777\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[205]\ttrain's rmse: 0.436344\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[149]\ttrain's rmse: 0.437741\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[72]\ttrain's rmse: 0.438697\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[245]\ttrain's rmse: 0.438665\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[57]\ttrain's rmse: 0.437427\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[100]\ttrain's rmse: 0.438512\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[101]\ttrain's rmse: 0.438753\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[92]\ttrain's rmse: 0.439334\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[113]\ttrain's rmse: 0.43608\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[106]\ttrain's rmse: 0.438382\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[172]\ttrain's rmse: 0.435578\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[174]\ttrain's rmse: 0.435964\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[310]\ttrain's rmse: 0.436095\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[190]\ttrain's rmse: 0.438306\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[171]\ttrain's rmse: 0.43725\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[243]\ttrain's rmse: 0.437856\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[132]\ttrain's rmse: 0.437204\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[99]\ttrain's rmse: 0.437874\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[57]\ttrain's rmse: 0.438771\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[169]\ttrain's rmse: 0.437589\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[82]\ttrain's rmse: 0.436504\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[133]\ttrain's rmse: 0.437505\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[56]\ttrain's rmse: 0.444222\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.437772\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[73]\ttrain's rmse: 0.436607\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[93]\ttrain's rmse: 0.436689\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[164]\ttrain's rmse: 0.4384\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[164]\ttrain's rmse: 0.437429\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[223]\ttrain's rmse: 0.43682\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[269]\ttrain's rmse: 0.437135\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[341]\ttrain's rmse: 0.437421\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[211]\ttrain's rmse: 0.436344\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[128]\ttrain's rmse: 0.440937\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[117]\ttrain's rmse: 0.435933\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[114]\ttrain's rmse: 0.438655\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[84]\ttrain's rmse: 0.436938\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[152]\ttrain's rmse: 0.435417\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[101]\ttrain's rmse: 0.437093\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.435926\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[143]\ttrain's rmse: 0.435727\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[148]\ttrain's rmse: 0.437271\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[195]\ttrain's rmse: 0.436667\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[126]\ttrain's rmse: 0.438359\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[110]\ttrain's rmse: 0.448222\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[272]\ttrain's rmse: 0.43732\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[80]\ttrain's rmse: 0.438873\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[155]\ttrain's rmse: 0.435837\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[183]\ttrain's rmse: 0.437595\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[244]\ttrain's rmse: 0.43688\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[236]\ttrain's rmse: 0.436981\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[127]\ttrain's rmse: 0.43752\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[165]\ttrain's rmse: 0.43603\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[112]\ttrain's rmse: 0.436811\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[144]\ttrain's rmse: 0.435779\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[95]\ttrain's rmse: 0.436973\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[161]\ttrain's rmse: 0.439258\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.436452\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[210]\ttrain's rmse: 0.435472\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[181]\ttrain's rmse: 0.436302\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[206]\ttrain's rmse: 0.437181\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[342]\ttrain's rmse: 0.437399\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[117]\ttrain's rmse: 0.437528\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[207]\ttrain's rmse: 0.436653\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[192]\ttrain's rmse: 0.437759\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[150]\ttrain's rmse: 0.437691\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[134]\ttrain's rmse: 0.437219\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[180]\ttrain's rmse: 0.437199\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[127]\ttrain's rmse: 0.436274\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[151]\ttrain's rmse: 0.436942\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[190]\ttrain's rmse: 0.435783\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[199]\ttrain's rmse: 0.438932\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[481]\ttrain's rmse: 0.437516\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[262]\ttrain's rmse: 0.436532\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[201]\ttrain's rmse: 0.435839\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.436638\nBest trial: score 0.4347034177780257, params {'max_depth': 10, 'learning_rate': 0.015300466767438051, 'lambda_l1': 0.0008167764841463397, 'lambda_l2': 0.0723899898589398, 'num_leaves': 9}\nFor wording and fold 0\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.699402\n[2000]\ttrain's rmse: 0.668095\n[3000]\ttrain's rmse: 0.656822\n[4000]\ttrain's rmse: 0.650418\nEarly stopping, best iteration is:\n[4633]\ttrain's rmse: 0.647481\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[163]\ttrain's rmse: 0.64321\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[432]\ttrain's rmse: 0.63336\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.644177\n[2000]\ttrain's rmse: 0.628257\nEarly stopping, best iteration is:\n[2026]\ttrain's rmse: 0.628187\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[909]\ttrain's rmse: 0.63595\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[425]\ttrain's rmse: 0.638576\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[123]\ttrain's rmse: 0.641361\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[166]\ttrain's rmse: 0.644231\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[234]\ttrain's rmse: 0.629331\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[248]\ttrain's rmse: 0.639843\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.633299\nEarly stopping, best iteration is:\n[1091]\ttrain's rmse: 0.632286\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[326]\ttrain's rmse: 0.64425\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.68684\nEarly stopping, best iteration is:\n[1453]\ttrain's rmse: 0.679366\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[477]\ttrain's rmse: 0.636847\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.637235\nEarly stopping, best iteration is:\n[1159]\ttrain's rmse: 0.634244\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[897]\ttrain's rmse: 0.640834\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[623]\ttrain's rmse: 0.631674\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.638383\nEarly stopping, best iteration is:\n[1075]\ttrain's rmse: 0.637359\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.645807\nEarly stopping, best iteration is:\n[1204]\ttrain's rmse: 0.640231\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[384]\ttrain's rmse: 0.644458\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.639472\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[798]\ttrain's rmse: 0.634429\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.63325\nEarly stopping, best iteration is:\n[1214]\ttrain's rmse: 0.630921\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[546]\ttrain's rmse: 0.638322\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[769]\ttrain's rmse: 0.63752\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[531]\ttrain's rmse: 0.634234\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[134]\ttrain's rmse: 0.638479\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.639499\nEarly stopping, best iteration is:\n[1073]\ttrain's rmse: 0.63813\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[596]\ttrain's rmse: 0.634179\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.672996\nEarly stopping, best iteration is:\n[1461]\ttrain's rmse: 0.661652\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[836]\ttrain's rmse: 0.636298\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[709]\ttrain's rmse: 0.62687\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.633408\nEarly stopping, best iteration is:\n[1208]\ttrain's rmse: 0.631716\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.640602\nEarly stopping, best iteration is:\n[1858]\ttrain's rmse: 0.627814\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.642848\nEarly stopping, best iteration is:\n[1600]\ttrain's rmse: 0.630753\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[829]\ttrain's rmse: 0.646291\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[795]\ttrain's rmse: 0.630576\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[479]\ttrain's rmse: 0.636255\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.634814\nEarly stopping, best iteration is:\n[1170]\ttrain's rmse: 0.630598\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[901]\ttrain's rmse: 0.644732\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[452]\ttrain's rmse: 0.627787\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[728]\ttrain's rmse: 0.631908\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[719]\ttrain's rmse: 0.636838\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[496]\ttrain's rmse: 0.629349\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[622]\ttrain's rmse: 0.632253\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[961]\ttrain's rmse: 0.642082\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[401]\ttrain's rmse: 0.63433\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[879]\ttrain's rmse: 0.631211\nTraining until validation scores don't improve for 30 rounds\n[1000]\ttrain's rmse: 0.689868\nEarly stopping, best iteration is:\n[1461]\ttrain's rmse: 0.681371\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[367]\ttrain's rmse: 0.63266\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[418]\ttrain's rmse: 0.630247\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[404]\ttrain's rmse: 0.631911\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[401]\ttrain's rmse: 0.626076\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[511]\ttrain's rmse: 0.62596\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[564]\ttrain's rmse: 0.62855\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[456]\ttrain's rmse: 0.632861\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[500]\ttrain's rmse: 0.631264\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[888]\ttrain's rmse: 0.632037\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[701]\ttrain's rmse: 0.636578\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[552]\ttrain's rmse: 0.629072\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[897]\ttrain's rmse: 0.635438\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[529]\ttrain's rmse: 0.623754\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[417]\ttrain's rmse: 0.625031\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[393]\ttrain's rmse: 0.627744\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[352]\ttrain's rmse: 0.630757\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[466]\ttrain's rmse: 0.628603\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[558]\ttrain's rmse: 0.62728\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[436]\ttrain's rmse: 0.625593\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[534]\ttrain's rmse: 0.635286\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[456]\ttrain's rmse: 0.623025\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[294]\ttrain's rmse: 0.63717\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[548]\ttrain's rmse: 0.627547\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[401]\ttrain's rmse: 0.63306\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[582]\ttrain's rmse: 0.625515\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[258]\ttrain's rmse: 0.634594\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[343]\ttrain's rmse: 0.638071\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[306]\ttrain's rmse: 0.633474\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[460]\ttrain's rmse: 0.626472\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[501]\ttrain's rmse: 0.63198\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[396]\ttrain's rmse: 0.631313\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[483]\ttrain's rmse: 0.62508\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[479]\ttrain's rmse: 0.628538\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[499]\ttrain's rmse: 0.628064\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[333]\ttrain's rmse: 0.628336\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[359]\ttrain's rmse: 0.632146\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[541]\ttrain's rmse: 0.628996\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[554]\ttrain's rmse: 0.624939\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[470]\ttrain's rmse: 0.631844\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[510]\ttrain's rmse: 0.63036\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[322]\ttrain's rmse: 0.629038\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[564]\ttrain's rmse: 0.62911\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[428]\ttrain's rmse: 0.625874\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[520]\ttrain's rmse: 0.626753\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[444]\ttrain's rmse: 0.626829\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[493]\ttrain's rmse: 0.627521\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[765]\ttrain's rmse: 0.623675\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[779]\ttrain's rmse: 0.632081\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[714]\ttrain's rmse: 0.624701\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[870]\ttrain's rmse: 0.623358\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[741]\ttrain's rmse: 0.635086\nBest trial: score 0.6230254022461152, params {'max_depth': 15, 'learning_rate': 0.047713044032329066, 'lambda_l1': 6.093058164899068, 'lambda_l2': 0.8775618364686774, 'num_leaves': 8}\nFor wording and fold 1\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[66]\ttrain's rmse: 0.764878\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[30]\ttrain's rmse: 0.766361\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.732182\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[24]\ttrain's rmse: 0.736698\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.722658\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[63]\ttrain's rmse: 0.72861\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.720221\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.714471\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.715741\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[11]\ttrain's rmse: 0.729964\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.716374\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.71526\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.716801\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.717034\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[24]\ttrain's rmse: 0.716983\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.71771\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[11]\ttrain's rmse: 0.715692\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.729778\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[18]\ttrain's rmse: 0.716586\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[25]\ttrain's rmse: 0.719285\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.71593\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[10]\ttrain's rmse: 0.716432\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[11]\ttrain's rmse: 0.716328\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[9]\ttrain's rmse: 0.721394\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.717816\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[10]\ttrain's rmse: 0.715715\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.717702\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.715134\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.717465\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.724666\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[19]\ttrain's rmse: 0.718577\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.7152\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.718502\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.715363\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[12]\ttrain's rmse: 0.715223\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[11]\ttrain's rmse: 0.717593\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[40]\ttrain's rmse: 0.764256\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[10]\ttrain's rmse: 0.717813\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.719585\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.729174\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[11]\ttrain's rmse: 0.718386\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.71514\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.715191\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.716226\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.732902\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[10]\ttrain's rmse: 0.717875\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.714308\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.715938\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713583\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713863\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.719628\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.71754\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.719748\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.719073\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[19]\ttrain's rmse: 0.718628\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713111\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.719884\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[19]\ttrain's rmse: 0.718452\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.726727\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.720109\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.714069\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.714069\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.719409\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713131\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[19]\ttrain's rmse: 0.718709\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713124\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[21]\ttrain's rmse: 0.719469\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[19]\ttrain's rmse: 0.719043\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.717559\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713102\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.719895\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.715771\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.71308\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713098\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.719996\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.717498\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.720918\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.722455\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.716893\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[23]\ttrain's rmse: 0.721851\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.715993\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713863\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.715071\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.715477\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.715324\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.720573\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[18]\ttrain's rmse: 0.72019\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.71243\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.716867\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[16]\ttrain's rmse: 0.716252\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.716665\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.717521\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713101\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.715313\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.719936\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[17]\ttrain's rmse: 0.715921\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[14]\ttrain's rmse: 0.723313\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[15]\ttrain's rmse: 0.713126\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[20]\ttrain's rmse: 0.725303\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[13]\ttrain's rmse: 0.717436\nBest trial: score 0.7124301504970952, params {'max_depth': 20, 'learning_rate': 0.057615406361674476, 'lambda_l1': 2.453903728589425e-07, 'lambda_l2': 0.026879711034730688, 'num_leaves': 9}\nFor wording and fold 2\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[203]\ttrain's rmse: 0.569806\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[551]\ttrain's rmse: 0.699734\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[166]\ttrain's rmse: 0.547484\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[504]\ttrain's rmse: 0.557665\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[179]\ttrain's rmse: 0.540203\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[185]\ttrain's rmse: 0.547509\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[433]\ttrain's rmse: 0.541606\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[540]\ttrain's rmse: 0.563494\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[285]\ttrain's rmse: 0.543396\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[253]\ttrain's rmse: 0.540836\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[208]\ttrain's rmse: 0.55328\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[212]\ttrain's rmse: 0.54156\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[176]\ttrain's rmse: 0.547447\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[355]\ttrain's rmse: 0.543559\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[188]\ttrain's rmse: 0.548811\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[206]\ttrain's rmse: 0.540509\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[249]\ttrain's rmse: 0.542989\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[168]\ttrain's rmse: 0.541584\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[332]\ttrain's rmse: 0.537464\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[182]\ttrain's rmse: 0.542897\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[193]\ttrain's rmse: 0.539721\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[188]\ttrain's rmse: 0.542793\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[192]\ttrain's rmse: 0.554854\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[170]\ttrain's rmse: 0.542609\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[278]\ttrain's rmse: 0.563001\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[196]\ttrain's rmse: 0.544871\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[249]\ttrain's rmse: 0.561151\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[225]\ttrain's rmse: 0.560131\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[156]\ttrain's rmse: 0.542556\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[207]\ttrain's rmse: 0.536922\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[238]\ttrain's rmse: 0.538119\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[189]\ttrain's rmse: 0.54102\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[172]\ttrain's rmse: 0.545127\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[225]\ttrain's rmse: 0.55749\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[134]\ttrain's rmse: 0.55124\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[195]\ttrain's rmse: 0.538622\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[189]\ttrain's rmse: 0.542961\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[149]\ttrain's rmse: 0.54207\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[158]\ttrain's rmse: 0.5402\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[171]\ttrain's rmse: 0.550314\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[209]\ttrain's rmse: 0.54599\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[363]\ttrain's rmse: 0.604238\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[256]\ttrain's rmse: 0.548339\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[213]\ttrain's rmse: 0.546592\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[170]\ttrain's rmse: 0.539718\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[261]\ttrain's rmse: 0.543961\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[211]\ttrain's rmse: 0.550966\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[274]\ttrain's rmse: 0.539755\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[261]\ttrain's rmse: 0.54267\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[197]\ttrain's rmse: 0.544886\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[176]\ttrain's rmse: 0.545808\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[199]\ttrain's rmse: 0.544261\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[201]\ttrain's rmse: 0.562107\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[231]\ttrain's rmse: 0.546269\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[189]\ttrain's rmse: 0.547845\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[277]\ttrain's rmse: 0.543335\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[184]\ttrain's rmse: 0.544247\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[195]\ttrain's rmse: 0.544927\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[192]\ttrain's rmse: 0.539236\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[220]\ttrain's rmse: 0.541721\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[189]\ttrain's rmse: 0.539277\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[116]\ttrain's rmse: 0.540727\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[149]\ttrain's rmse: 0.546522\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[252]\ttrain's rmse: 0.562567\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[269]\ttrain's rmse: 0.543248\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[184]\ttrain's rmse: 0.53873\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[188]\ttrain's rmse: 0.548639\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[180]\ttrain's rmse: 0.541928\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.543667\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[171]\ttrain's rmse: 0.546341\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[178]\ttrain's rmse: 0.541344\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[219]\ttrain's rmse: 0.541886\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[209]\ttrain's rmse: 0.544495\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[246]\ttrain's rmse: 0.546999\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[242]\ttrain's rmse: 0.553472\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[160]\ttrain's rmse: 0.540646\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[197]\ttrain's rmse: 0.542867\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[184]\ttrain's rmse: 0.54495\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[159]\ttrain's rmse: 0.541485\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[242]\ttrain's rmse: 0.538186\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.544942\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[211]\ttrain's rmse: 0.550014\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[248]\ttrain's rmse: 0.549768\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[157]\ttrain's rmse: 0.538575\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.543058\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[175]\ttrain's rmse: 0.54234\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[223]\ttrain's rmse: 0.542633\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[131]\ttrain's rmse: 0.540334\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[196]\ttrain's rmse: 0.541842\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[146]\ttrain's rmse: 0.54422\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[263]\ttrain's rmse: 0.567617\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[213]\ttrain's rmse: 0.546521\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[153]\ttrain's rmse: 0.5431\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[209]\ttrain's rmse: 0.539258\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[216]\ttrain's rmse: 0.5542\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[232]\ttrain's rmse: 0.539721\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[171]\ttrain's rmse: 0.538381\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[219]\ttrain's rmse: 0.537102\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[271]\ttrain's rmse: 0.534397\nTraining until validation scores don't improve for 30 rounds\nEarly stopping, best iteration is:\n[248]\ttrain's rmse: 0.555593\nBest trial: score 0.5343974677515146, params {'max_depth': 11, 'learning_rate': 0.08838335424749512, 'lambda_l1': 0.005877933147791426, 'lambda_l2': 5.4480330419544034e-05, 'num_leaves': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"def adjust_predictions(X, main_model, post_process_model, top_features):\n    main_pred = main_model.predict(X)\n    #dtest = xgb.DMatrix(X[top_features])\n    adjustment_values = post_process_model.predict(X[top_features])\n    print(main_pred)\n    print(adjustment_values)\n    return main_pred + adjustment_values","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:13.633053Z","iopub.execute_input":"2023-10-01T11:47:13.633521Z","iopub.status.idle":"2023-10-01T11:47:13.638345Z","shell.execute_reply.started":"2023-10-01T11:47:13.633493Z","shell.execute_reply":"2023-10-01T11:47:13.637418Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# cv\nrmses = []\n\nfor target in targets:\n    models = model_dict[target]['main_models']\n\n    preds = []\n    trues = []\n    \n    for fold, model in enumerate(models):\n        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n        y_eval_cv = train[train[\"fold\"] == fold][target]\n\n        pred = model.predict(X_eval_cv)\n\n        trues.extend(y_eval_cv)\n        preds.extend(pred)\n        \n    rmse = np.sqrt(mean_squared_error(trues, preds))\n    print(f\"{target}_rmse : {rmse}\")\n    rmses = rmses + [rmse]\n\nprint(f\"mcrmse : {sum(rmses) / len(rmses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:13.639696Z","iopub.execute_input":"2023-10-01T11:47:13.640343Z","iopub.status.idle":"2023-10-01T11:47:13.832011Z","shell.execute_reply.started":"2023-10-01T11:47:13.640306Z","shell.execute_reply":"2023-10-01T11:47:13.831032Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"content_rmse : 0.473593153079758\nwording_rmse : 0.6269464405628608\nmcrmse : 0.5502697968213094\n","output_type":"stream"}]},{"cell_type":"code","source":"for target in targets:\n    adj_preds = []\n    adj_trues = []\n    for fold in range(CFG.n_splits):\n        print(f'For {target} and fold {fold}')\n        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n        y_eval_cv = train[train[\"fold\"] == fold][target]\n        main_model = model_dict[target][\"main_models\"][fold]\n        post_model = model_dict[target][\"post_models\"][fold]\n        top_features_for_fold  =  model_dict[target][\"top_features\"][fold]\n        adjusted_preds = adjust_predictions(X_eval_cv, main_model, post_model, top_features_for_fold)\n        adj_trues.extend(y_eval_cv)\n        adj_preds.extend(adjusted_preds)\n        \n    rmse = np.sqrt(mean_squared_error(adj_trues, adj_preds))\n    print(f\"{target}_rmse : {rmse}\")\n    rmses = rmses + [rmse]\n    \nprint(f\"mcrmse : {sum(rmses) / len(rmses)}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:13.833775Z","iopub.execute_input":"2023-10-01T11:47:13.834091Z","iopub.status.idle":"2023-10-01T11:47:14.119685Z","shell.execute_reply.started":"2023-10-01T11:47:13.834054Z","shell.execute_reply":"2023-10-01T11:47:14.118631Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"For content and fold 0\n[-0.08591465  2.20268918 -0.12398932 ...  1.68067757 -0.27837908\n -0.37692698]\n[0.05325427 0.78904307 0.04733507 ... 0.4629864  0.08407933 0.01785106]\nFor content and fold 1\n[ 2.260857   -0.95026464  0.34885964 ...  0.53150487 -0.23976734\n -0.22056285]\n[ 0.30741692 -0.09709336 -0.52047276 ... -0.07599487 -0.13985902\n -0.43074024]\nFor content and fold 2\n[-0.42549884 -0.76803258 -0.63832177 ...  0.47517993 -0.30347078\n  0.7730632 ]\n[-0.03480146  0.35953164  0.08014546 ...  0.06225091  0.07976427\n  0.3645098 ]\ncontent_rmse : 0.37299035044478734\nFor wording and fold 0\n[ 0.56316995  2.05459527  0.11974757 ...  0.98129833 -0.41767359\n  0.08998563]\n[3.8479808e-01 3.8479808e-01 2.1898717e-04 ... 3.8479808e-01 2.1898717e-04\n 2.1898717e-04]\nFor wording and fold 1\n[ 1.17222953 -0.39856105  0.43717492 ...  0.57256657  0.03778151\n  0.08617045]\n[ 1.5045826  -0.39562267 -0.03379241 ... -0.31459117 -0.01240441\n -0.01027669]\nFor wording and fold 2\n[ 0.23524524  0.06230033 -0.01215128 ...  0.15167436 -0.21558092\n  0.95679756]\n[-0.17995977 -0.07314163 -0.1682463  ... -0.26609746 -0.04157943\n -0.3641406 ]\nwording_rmse : 0.5347610116441556\nmcrmse : 0.5020727389328904\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create Submission Infomration","metadata":{}},{"cell_type":"code","source":"# drop_columns = [\n#                 #\"fold\", \n#                 \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n#                 \"prompt_question\", \"prompt_title\", \n#                 \"prompt_text\",\n#                 \"input\"\n#                ] + [\n#                 f\"content_pred_{i}\" for i in range(CFG.n_splits)\n#                 ] + [\n#                 f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n#                 ]\n\n\ndrop_columns = [\n                #\"fold\", \n                \"student_id\", \"prompt_id\", \"text\",\n                \"prompt_question\", \"prompt_title\", \n                \"prompt_text\",\"title\", \"author\", \"description\", \"genre\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:14.121369Z","iopub.execute_input":"2023-10-01T11:47:14.121958Z","iopub.status.idle":"2023-10-01T11:47:14.127870Z","shell.execute_reply.started":"2023-10-01T11:47:14.121903Z","shell.execute_reply":"2023-10-01T11:47:14.126561Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"pred_dict = {}\n\nfor target in targets:\n    models = model_dict[target][\"main_models\"]\n    post_models = model_dict[target][\"post_models\"]\n    top_features_list = model_dict[target][\"top_features\"]\n    preds = []\n\n    for fold, (model, post_model, top_features) in enumerate(zip(models, post_models, top_features_list)):\n        X_eval_cv = test.drop(columns=drop_columns)\n        #X_eval_cv.fillna(0,inplace=True)\n        pred = adjust_predictions(X_eval_cv, model, post_model, top_features)\n        preds.append(pred)\n    \n    pred_dict[target] = preds\n    \nfor target in targets:\n    preds = pred_dict[target]\n    for i, pred in enumerate(preds):\n        test[f\"{target}_pred_{i}\"] = pred\n\n    # Calculate the median across the K-Fold predictions\n    medians = test[[f'{target}_pred_{fold}' for fold in range(CFG.n_splits)]].median(axis=1)\n\n    # Calculate the standard deviation across the K-Fold predictions\n    std_devs = test[[f'{target}_pred_{fold}' for fold in range(CFG.n_splits)]].std(axis=1)\n\n    # Adjust the median using the standard deviation\n    adjusted_medians = medians + (CFG.adjustment_factor * std_devs)\n\n    test[target] = adjusted_medians\n\n    print(test)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:14.128789Z","iopub.execute_input":"2023-10-01T11:47:14.129004Z","iopub.status.idle":"2023-10-01T11:47:14.228302Z","shell.execute_reply.started":"2023-10-01T11:47:14.128968Z","shell.execute_reply":"2023-10-01T11:47:14.227346Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[-1.48745238 -1.48745238 -1.48745238 -1.48745238]\n[-0.40551642 -0.40551642 -0.40551642 -0.40551642]\n[-0.83593238 -0.83593238 -0.83593238 -0.83593238]\n[-1.7302157 -1.7302157 -1.7302157 -1.7302157]\n[-1.36687625 -1.36687625 -1.36687625 -1.36687625]\n[-0.07307541 -0.07307541 -0.07307541 -0.07307541]\n[-1.24134365 -1.24134365 -1.24134365 -1.24134365]\n[0.00021899 0.00021899 0.00021899 0.00021899]\n[0.95691048 0.95691048 0.95691048 0.95691048]\n[-0.4262491 -0.4262491 -0.4262491 -0.4262491]\n[-1.7255097 -1.7255097 -1.7255097 -1.7255097]\n[-0.38556734 -0.38556734 -0.38556734 -0.38556734]\n     student_id prompt_id            text  summary_length  splling_err_num  \\\n0  000000ffffff    abc123  Example text 1               3                0   \n1  111111eeeeee    def789  Example text 2               3                0   \n2  222222cccccc    abc123  Example text 3               3                0   \n3  333333dddddd    def789  Example text 4               3                0   \n\n  prompt_question     prompt_title       prompt_text title author  ...  pos  \\\n0    Summarize...  Example Title 1  Heading\\nText...   NaN    NaN  ...  0.0   \n1    Summarize...  Example Title 2  Heading\\nText...   NaN    NaN  ...  0.0   \n2    Summarize...  Example Title 1  Heading\\nText...   NaN    NaN  ...  0.0   \n3    Summarize...  Example Title 2  Heading\\nText...   NaN    NaN  ...  0.0   \n\n  compound neg_prompt  neu_prompt  pos_prompt  compound_prompt  \\\n0      0.0        0.0         1.0         0.0              0.0   \n1      0.0        0.0         1.0         0.0              0.0   \n2      0.0        0.0         1.0         0.0              0.0   \n3      0.0        0.0         1.0         0.0              0.0   \n\n   content_pred_0  content_pred_1  content_pred_2   content  \n0       -1.892969       -2.566148       -1.439952 -1.609632  \n1       -1.892969       -2.566148       -1.439952 -1.609632  \n2       -1.892969       -2.566148       -1.439952 -1.609632  \n3       -1.892969       -2.566148       -1.439952 -1.609632  \n\n[4 rows x 63 columns]\n     student_id prompt_id            text  summary_length  splling_err_num  \\\n0  000000ffffff    abc123  Example text 1               3                0   \n1  111111eeeeee    def789  Example text 2               3                0   \n2  222222cccccc    abc123  Example text 3               3                0   \n3  333333dddddd    def789  Example text 4               3                0   \n\n  prompt_question     prompt_title       prompt_text title author  ...  \\\n0    Summarize...  Example Title 1  Heading\\nText...   NaN    NaN  ...   \n1    Summarize...  Example Title 2  Heading\\nText...   NaN    NaN  ...   \n2    Summarize...  Example Title 1  Heading\\nText...   NaN    NaN  ...   \n3    Summarize...  Example Title 2  Heading\\nText...   NaN    NaN  ...   \n\n  pos_prompt compound_prompt content_pred_0  content_pred_1  content_pred_2  \\\n0        0.0             0.0      -1.892969       -2.566148       -1.439952   \n1        0.0             0.0      -1.892969       -2.566148       -1.439952   \n2        0.0             0.0      -1.892969       -2.566148       -1.439952   \n3        0.0             0.0      -1.892969       -2.566148       -1.439952   \n\n    content  wording_pred_0  wording_pred_1  wording_pred_2   wording  \n0 -1.609632       -1.241125        0.530661       -2.111077 -0.567984  \n1 -1.609632       -1.241125        0.530661       -2.111077 -0.567984  \n2 -1.609632       -1.241125        0.530661       -2.111077 -0.567984  \n3 -1.609632       -1.241125        0.530661       -2.111077 -0.567984  \n\n[4 rows x 67 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# pred_dict = {}\n# for target in targets:\n#     models = model_dict[target]\n#     preds = []\n\n#     for fold, model in enumerate(models):\n#         X_eval_cv = test.drop(columns=drop_columns)\n\n#         pred = model.predict(X_eval_cv)\n#         preds.append(pred)\n    \n#     pred_dict[target] = preds\n    \n    \n# for target in targets:\n#     preds = pred_dict[target]\n#     for i, pred in enumerate(preds):\n#         test[f\"{target}_pred_{i}\"] = pred\n\n#     # Calculate the median across the K-Fold predictions\n#     medians = test[[f'{target}_pred_{fold}' for fold in range(CFG.n_splits)]].median(axis=1)\n\n#     # Calculate the standard deviation across the K-Fold predictions\n#     std_devs = test[[f'{target}_pred_{fold}' for fold in range(CFG.n_splits)]].std(axis=1)\n\n#     # Adjust the median using the standard deviation\n#     adjusted_medians = medians + (CFG.adjustment_factor * std_devs)\n\n#     test[target] = adjusted_medians\n\n#     print(test)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:14.229566Z","iopub.execute_input":"2023-10-01T11:47:14.229813Z","iopub.status.idle":"2023-10-01T11:47:14.235296Z","shell.execute_reply.started":"2023-10-01T11:47:14.229787Z","shell.execute_reply":"2023-10-01T11:47:14.233913Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:14.236367Z","iopub.execute_input":"2023-10-01T11:47:14.236580Z","iopub.status.idle":"2023-10-01T11:47:14.255444Z","shell.execute_reply.started":"2023-10-01T11:47:14.236556Z","shell.execute_reply":"2023-10-01T11:47:14.254664Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!touch submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-10-01T11:47:14.256412Z","iopub.execute_input":"2023-10-01T11:47:14.257277Z","iopub.status.idle":"2023-10-01T11:47:15.412694Z","shell.execute_reply.started":"2023-10-01T11:47:14.257247Z","shell.execute_reply":"2023-10-01T11:47:15.411542Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}